{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7fa895-fb36-4146-b2d3-e04dbd1cd84e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T10:11:54.048015Z",
     "iopub.status.busy": "2023-08-19T10:11:54.047479Z",
     "iopub.status.idle": "2023-08-19T10:11:54.053563Z",
     "shell.execute_reply": "2023-08-19T10:11:54.052425Z",
     "shell.execute_reply.started": "2023-08-19T10:11:54.047984Z"
    }
   },
   "source": [
    "# 基于脑PET图像的疾病预测挑战赛 CNN 版本\n",
    "\n",
    "在这个notebook中我们使用CNN来训练PET的图像识别，判定给定图像是否为MCI患者\n",
    "卷积神经网络（Convolutional Neural Network，CNN）是一种深度学习模型，广泛用于图像识别、计算机视觉和模式识别任务中。CNN 在处理具有网格结构数据（如图像）时表现出色，它能够自动学习和提取图像中的特征，并在分类、定位和分割等任务中取得优秀的性能。\n",
    "我们使用Pytorch CNN来完成训练。\n",
    "- CNN带来的精度更好，但需要训练更长的时间\n",
    "- CNN模型调优需要GPU\n",
    "\n",
    "\n",
    "## 步骤一 数据准备\n",
    "\n",
    "导入所需要的数据库和函数调用库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a7bab49-7d95-45eb-9673-1224886318d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T10:13:54.266236Z",
     "iopub.status.busy": "2023-08-19T10:13:54.265706Z",
     "iopub.status.idle": "2023-08-19T10:13:57.581910Z",
     "shell.execute_reply": "2023-08-19T10:13:57.580769Z",
     "shell.execute_reply.started": "2023-08-19T10:13:54.266204Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.douban.com/simple\n",
      "Requirement already satisfied: nibabel in c:\\users\\shucheng\\anaconda3\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\shucheng\\anaconda3\\lib\\site-packages (from nibabel) (1.22.4+mkl)\n",
      "Requirement already satisfied: packaging>=17 in c:\\users\\shucheng\\anaconda3\\lib\\site-packages (from nibabel) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\shucheng\\anaconda3\\lib\\site-packages (from packaging>=17->nibabel) (3.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "# nibabel 需要从一些其他的源来调用。。。\n",
    "!pip install nibabel -i https://pypi.douban.com/simple --trust -host=pypi.douban.com\n",
    "import glob                # 获取文件路径\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib      # 处理医学图像数据\n",
    "from nibabel.viewers import OrthoSlicer3D    # 图像可视化\n",
    "from collections import Counter              # 计数统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5298c3d-3db6-4420-8a9d-e0430c8d6a3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T10:34:35.901639Z",
     "iopub.status.busy": "2023-08-19T10:34:35.900484Z",
     "iopub.status.idle": "2023-08-19T10:34:35.913185Z",
     "shell.execute_reply": "2023-08-19T10:34:35.912035Z",
     "shell.execute_reply.started": "2023-08-19T10:34:35.901586Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, sys, glob, argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71321486-cf5a-4493-8b54-aea357882661",
   "metadata": {},
   "source": [
    "这里添加一些导入的库的说明：\n",
    "| Library / Module | Description | Common Features |\n",
    "|--------------|-------------|-----------------|\n",
    "| os           | Interact with the operating system | os.path.join(), os.listdir(), os.makedirs(), os.remove(), os.system(), os.getenv() |\n",
    "| sys          | Access interpreter variables and functions | sys.argv, sys.exit(), sys.platform, sys.path |\n",
    "| glob         | Find pathnames matching a pattern | glob.glob(), glob.iglob() |\n",
    "| argparse     | Parse command-line arguments | Argument parsing with flags, positional arguments, default values, help messages |\n",
    "| pandas       | Data manipulation and analysis | DataFrames, Series, data alignment, grouping, merging, handling missing data |\n",
    "| numpy        | Arrays, matrices, mathematical functions | Multidimensional arrays, array operations, broadcasting, linear algebra, random generation |\n",
    "| tqdm         | Progress bar for loops | Adding progress bars to loops using tqdm() function | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d7f3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\shucheng\\anaconda3\\lib\\site-packages (4.8.0.76)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\shucheng\\anaconda3\\lib\\site-packages (from opencv-python) (1.22.4+mkl)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d15696f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install torch -q\n",
    "# The install successful information can be annoying. can suppress by adding -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3dc9787-4c20-4549-a610-b7dc6de07e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T10:34:39.675835Z",
     "iopub.status.busy": "2023-08-19T10:34:39.674814Z",
     "iopub.status.idle": "2023-08-19T10:34:39.680162Z",
     "shell.execute_reply": "2023-08-19T10:34:39.679400Z",
     "shell.execute_reply.started": "2023-08-19T10:34:39.675793Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2 #this needs opencv-python first, see above\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "import torch #this needs install torch first, see above\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaba70c-86cd-4f60-979a-407ba75f8df1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "| Library / Module | Description | Common Features |\n",
    "|--------------|-------------|-----------------|\n",
    "| cv2                       | OpenCV library for computer vision         | Image processing, computer vision tasks, video capture and analysis                                                |\n",
    "| PIL (Image module)        | Python Imaging Library for image processing | Opening, manipulating, and saving various image formats                                                            |\n",
    "| sklearn.model_selection  | Scikit-learn module for data splitting     | Data splitting for training and testing, cross-validation, stratified sampling, k-fold cross-validation            |\n",
    "| torch                     | PyTorch library for deep learning          | Tensors, neural network modules, optimization algorithms, autograd for automatic differentiation                  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0f2f6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c6c6886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bd32d31-630a-471f-905c-d0c265a8f7bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-19T10:34:21.377160Z",
     "iopub.status.busy": "2023-08-19T10:34:21.376051Z",
     "iopub.status.idle": "2023-08-19T10:34:21.382330Z",
     "shell.execute_reply": "2023-08-19T10:34:21.381197Z",
     "shell.execute_reply.started": "2023-08-19T10:34:21.377114Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models \n",
    "##before do this still need to install torchvision, this is separate extension library to torch \n",
    "# with tools specific to computer vision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "# This is the Dataset class we will use later!! (The parent class of XunFeiDataSet)\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# This is the nii imaging package. used to read nii images\n",
    "import nibabel as nib\n",
    "from nibabel.viewers import OrthoSlicer3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d149009a-250b-4191-b3a8-bf85d37abeef",
   "metadata": {},
   "source": [
    "| Library Name            | Description                                   | Common Features                                                                           |\n",
    "|-------------------------|-----------------------------------------------|--------------------------------------------------------------------------------------------|\n",
    "| torchvision.models      | Models and pre-trained models in PyTorch     | Various pre-defined deep learning models for image classification and feature extraction |\n",
    "| torchvision.transforms  | Data transformations for images in PyTorch   | Image data augmentation, normalization, resizing, cropping, and more                     |\n",
    "| torchvision.datasets   | Datasets for PyTorch                          | Access to standard datasets for training and testing, data loaders                        |\n",
    "| torch.nn (nn module)    | Neural network layers and modules in PyTorch | Layers, activation functions, loss functions, optimizers, custom module definitions       |\n",
    "| torch.nn.functional    | Functional interface to nn modules in PyTorch | Functional alternatives to some nn module operations                                      |\n",
    "| torch.optim            | Optimization algorithms in PyTorch           | SGD, Adam (adaptive moment estimation, an extension of SGD), RMSprop, optimization functions                                                 |\n",
    "| torch.autograd         | Automatic differentiation in PyTorch        | Computing gradients for gradient-based optimization                                       |\n",
    "| torch.utils.data.dataset | Dataset class in PyTorch                    | Custom dataset creation for data loading and preprocessing                               |\n",
    "| nibabel.viewers | methods for analysing nii images | OrthoSlicer3D: taking slices of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b5526a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\shucheng\\anaconda3\\lib\\site-packages (4.8.0.76)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\shucheng\\anaconda3\\lib\\site-packages (from opencv-python) (1.22.4+mkl)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "# An import library for CV\n",
    "pip install --user opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c969b7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "# albumentations is a library built on top of opencv, and focuses specifically on efficient and customizable image\n",
    "# augmentation for machine learning and deep learning tasks. It streamlines the process of applying complex \n",
    "# augmentation pipelines to large datasets while utilizing the powerful image processing capabilities of OpenCV.\n",
    "%pip install --user albumentations -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ed4ea6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf4d0a9",
   "metadata": {},
   "source": [
    "| Library Name     | Description                                      | Common Features                                                                                |\n",
    "|------------------|--------------------------------------------------|------------------------------------------------------------------------------------------------|\n",
    "| albumentations   | Image augmentation library for machine learning | Wide range of image augmentation techniques, compatible with various deep learning frameworks (compared with opencv \"more user friendly\") |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924a540",
   "metadata": {},
   "source": [
    "需要用的库已经导入完毕，接下来开始导入并处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5868421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = glob.glob('./PETdata/train/*/*')\n",
    "# 仍然，注意到Train文件夹下有MCI和NC两个附属文件夹，里面的文件都需要读取，用/*/*\n",
    "test_path = glob.glob('./PETdata/Test/*')\n",
    "\n",
    "np.random.shuffle(train_path)\n",
    "np.random.shuffle(test_path)\n",
    "\n",
    "# DATA_CACHE is a dictionary. The keys are path names, the values are np3darray (dataobj of nib images)\n",
    "# The DATA_CACHE is a dictionary used for caching loaded images.\n",
    "DATA_CACHE = {}\n",
    "\n",
    "# 定义一个Class XunFeiDataset,参数是一堆需要处理的图像的paths(\"img_path\")，以及需要进行的图像变换(\"transform\")\n",
    "# 注意到定义时添加了parent class \"Dataset\" (torch.utils.data.Dataset)，这代表任何定义为属于XunFeiDataset class的实例都将同时继承Dataset class的methods\n",
    "# 前序进行了 from torch.utils.data.dataset import Dataset这里指的是torch library里叫做Dataset的class\n",
    "class XunFeiDataset(Dataset):\n",
    "    # 一个左侧加了双下划线的method是一个private method, private method不能直接被所属instance调用。具体参考onenote说明。\n",
    "    # 注意这里的__init__和__getitem__两侧都有双下划线不是说他们是private method，而说明他们是特殊的一种dunder method (double underline)\n",
    "    # 这里的__init__constructor method来初始化一个属于Class的instance的一些属性。\n",
    "    # 如self := IMAGES = XunFeiDataset(img_path = ['abc','def',....], transform = A.Compose([...]) 作为一个instance\n",
    "    # （一些Albumentation库中导入的transform的method的拼接，具体见下接的markdown),\n",
    "    # 那么IMAGES.img_path = ['abc','def','ghi',....], IMAGES.transform = A.Compose([...])\n",
    "    def __init__(self, img_path, transform=None):\n",
    "        self.img_path = img_path\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    # The __getitem__ method is used to implement indexing behavior for instances of the class. \n",
    "    # e.g. IMAGES[3] does the following: \n",
    "    # Check if the path given by IMAGES.img_path[3] is in DATA_CACHE: ...\n",
    "    # (if not using __getitem__ to define, can't type IMAGES[3], would have to type IMAGES.img_path[3] instead)\n",
    "    def __getitem__(self, index):\n",
    "        # Checks whether the specified path of (IMAGES.img_path[index]) is already present \n",
    "        # in the DATA_CACHE's keys.\n",
    "        if self.img_path[index] in DATA_CACHE:\n",
    "            # If the path is found in DATA_CACHE's keys, the corresponding cached np3darray image from the cache is loaded\n",
    "            # and assigned to the img variable.\n",
    "            img = DATA_CACHE[self.img_path[index]]\n",
    "        else:\n",
    "            # If the path is not in DATA_CACHE's keys, it uses the nib.load function from the nibabel library \n",
    "            # to load the NIfTI format image from the path specified by self.img_path[index] to the img variable.\n",
    "            img = nib.load(self.img_path[index]) \n",
    "            # img then accesses the dataobj attribute of the loaded image. \n",
    "            # The dataobj attribute contains the actual image data in a NumPy array-like object.\n",
    "            # The indexing [:, :, :, 0] is used to select data from the first volume (assuming the image is 4D), \n",
    "            # effectively extracting a 3D slice from the image (restriction to one coloring passage)\n",
    "            img = img.dataobj[:,:,:, 0]\n",
    "            # Finally, the loaded or extracted image is cached in the DATA_CACHE dictionary using the given path as the key.\n",
    "            DATA_CACHE[self.img_path[index]] = img\n",
    "    \n",
    "        # Then, a random of 50 slices of the 3Darray are selected (with replacement) \n",
    "        # and combined to make the updated img 3Darray      \n",
    "        idx = np.random.choice(range(img.shape[-1]), 50)\n",
    "        img = img[:, :, idx]\n",
    "        # Finally converts the data stored in the img 3Darray to floats for later use\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        # IMAGES是一个XunFeiDataset的实例（也继承成为Dataset的实例），\n",
    "        # if IMAGES.transform is not empty (e.g. see next code block, transform loads a class A.Compos\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image = img)['image']\n",
    "        \n",
    "        \n",
    "        # We take the transpose of the image tensor,\n",
    "        # make the z-coponent be inquired first\n",
    "        img = img.transpose([2,0,1])\n",
    "        return img,torch.from_numpy(np.array(int('NC' in self.img_path[index])))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfa6570",
   "metadata": {},
   "source": [
    "有关一些即将被导进“transform”这个参数的methods：他们到底是哪儿来的：\n",
    "\n",
    "| Method                  | Module                                               |\n",
    "|-------------------------|------------------------------------------------------|\n",
    "| A.RandomRotate90        | albumentations.augmentations.geometric.rotate       |\n",
    "| A.RandomCrop            | albumentations.augmentations.crops.transforms       |\n",
    "| A.HorizontalFlip        | albumentations.augmentations.geometric.transforms   |\n",
    "| A.RandomContrast        | albumentations.augmentations.transforms             |\n",
    "| A.RandomBrightnessContrast | albumentations.augmentations.transforms          |\n",
    "\n",
    "都是在albumentations库里，只不过藏得到处都是。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bbc67415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shucheng\\anaconda3\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1284: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train_loader is a DataLoader class instance, inheriting from the XunFeiDataset instance, inheriting from Dataset instance\n",
    "# It intakes a Dataset class instance (needs to be torch.utils.data.Dataset class) and \n",
    "# the sampling parameters: batch_size, shuffle, num_workers...\n",
    "# For the output, it provides an iterable over the Dataset instance.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    # this train_loader instance is filled with a XunFeiDataset class instance (which is, a Dataset Class instance), \n",
    "        ## with img_path defined to be all paths in the list train_path all but last ten images\n",
    "        ## and transform being the composition of those methods in albumentations library\n",
    "    # and sampling parameters: batch_size = 2, shuffle = True,...\n",
    "\n",
    "    # in the above context, this would mean self.transform = A.Compose([A.RandomRotate90(),...,A.RandomBrightnesContrast(p=0.5)])\n",
    "    XunFeiDataset(img_path = train_path[:-10], transform = \n",
    "            # These are methods for transforming images\n",
    "            A.Compose([\n",
    "            A.RandomRotate90(),\n",
    "            A.RandomCrop(120, 120),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomContrast(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "        ])\n",
    "        # The num_workers parameter specifies the number of worker processes to use for data loading. \n",
    "        # Each worker process loads a batch of data independently in parallel, which can significantly speed up data loading.\n",
    "        # The number of workers should be chosen based on your system's capabilities and the nature of the dataset.\n",
    "        # using too many workers could overload your CPU and RAM.\n",
    "\n",
    "        # Setting pin_memory to True is relevant when using GPUs for training. \n",
    "        # which can lead to faster data transfers between CPU and GPU.\n",
    "    ), batch_size=2, shuffle=True, num_workers=1, pin_memory=False\n",
    "    \n",
    ")\n",
    "\n",
    "# This is loading validation images... Still take sampling from XunFeiDataset instance, \n",
    "# but we only use the last ten paths in the train_path \n",
    "# Also this time only allow crops, \n",
    "# as true images we need to classify are never horizontally flipped, changed contrast etc.\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(train_path[-10:],\n",
    "            A.Compose([\n",
    "            A.RandomCrop(120, 120),\n",
    "        ])\n",
    "    ), batch_size=2, shuffle=False, num_workers=1, pin_memory=False\n",
    ")\n",
    "\n",
    "# This is loading test images... Still take sampling from XunFeiDataset instance,\n",
    "# but we use test_path\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(test_path,\n",
    "            A.Compose([\n",
    "            A.RandomCrop(128, 128),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomContrast(p=0.5),\n",
    "        ])\n",
    "    ), batch_size=2, shuffle=False, num_workers=1, pin_memory=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb90b252",
   "metadata": {},
   "source": [
    "## 步骤二 自定义CNN模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851a90a",
   "metadata": {},
   "source": [
    "这里XunFeiNet模型架构选择的是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bbd290bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a new class named XunFeiNet that inherits from nn.Module. \n",
    "# This means that XunFeiNet is a PyTorch neural network model.\n",
    "class XunFeiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # When calling super() with the subclass and an instance of that subclass (self), \n",
    "        # it allows you to access and call methods from its parent classes.\n",
    "        # Here, the code calls the constructor of the parent class (nn.Module) to properly initialize the class.\n",
    "        # This could also be done by nn.Module.__init__(self)\n",
    "        # However when class hierarchy is complicated, it's best to use \"super\" instead of calling parentclass.__init__(self)\n",
    "        # because \"super\" ensures that the constructors of all parent classes are called in the correct order.\n",
    "        super(XunFeiNet, self).__init__()\n",
    "\n",
    "        # creates an instance of the pre-trained ResNet-18 model using the models module from torchvision. \n",
    "        # The True argument specifies that the pre-trained weights should be loaded. (transfer learning)\n",
    "        model = models.resnet18(True)\n",
    "        # replaces the first convolutional layer of the ResNet-18 model with a new layer that takes 50 input channels \n",
    "        # (since there are 50 slices in each img.)\n",
    "        # instead of the default 3. The kernel size, stride, and padding are adjusted accordingly.\n",
    "        model.conv1 = torch.nn.Conv2d(50, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        # replaces the average pooling layer of the ResNet-18 model with an adaptive average pooling layer \n",
    "        # that produces output of size 1x1.\n",
    "        model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        # replaces the fully connected layer (last layer before softmax) of the ResNet-18 model with a new linear layer \n",
    "        # for binary classification (2 output classes)\n",
    "        model.fc = nn.Linear(512, 2)\n",
    "        self.resnet = model\n",
    "        \n",
    "    # defines the forward pass of the neural network\n",
    "    def forward(self, img): \n",
    "        # performs the forward pass by passing the input img through the modified ResNet-18 model,\n",
    "        # then return the output tensor\n",
    "        out = self.resnet(img)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = XunFeiNet()\n",
    "# moves the model to the GPU device for faster computation (assuming a GPU is available).\n",
    "# Cuda is not available on my system because I don't have a compatible NVIDIA GPU...\n",
    "# model = model.to('cuda')\n",
    "criterion = nn.CrossEntropyLoss()#.cuda()\n",
    "# creates the Cross-Entropy loss function and moves it to the GPU.\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 0.001)\n",
    "# initializes the AdamW optimizer to update the model's parameters during training using the specified learning rate (0.001)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c1b18",
   "metadata": {},
   "source": [
    "## 步骤三 模型训练与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8ad50fa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 16104) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Shucheng\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1132\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1133\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Shucheng\\anaconda3\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_37484/356426158.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m  \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mval_acc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_37484/356426158.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Shucheng\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Shucheng\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1328\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Shucheng\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1292\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1294\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1295\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Shucheng\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1143\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 16104) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        input = input.cuda(non_blocking=True)\n",
    "        target = target.cuda(non_blocking=True)\n",
    "\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print(loss.item())\n",
    "            \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    return train_loss/len(train_loader)\n",
    "            \n",
    "def validate(val_loader, model, criterion):\n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            val_acc += (output.argmax(1) == target).sum().item()\n",
    "            \n",
    "    return val_acc / len(val_loader.dataset)\n",
    "    \n",
    "for _  in range(3):\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_acc  = validate(val_loader, model, criterion)\n",
    "    train_acc = validate(train_loader, model, criterion)\n",
    "    \n",
    "    print(train_loss, train_acc, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd94bc1",
   "metadata": {},
   "source": [
    "## 步骤四 模型预测与生成csv结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_loader, model, criterion):\n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(test_loader):\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            output = model(input)\n",
    "            test_pred.append(output.data.cpu().numpy())\n",
    "            \n",
    "    return np.vstack(test_pred)\n",
    "    \n",
    "pred = None\n",
    "for _ in range(10):\n",
    "    if pred is None:\n",
    "        pred = predict(test_loader, model, criterion)\n",
    "    else:\n",
    "        pred += predict(test_loader, model, criterion)\n",
    "        \n",
    "submit = pd.DataFrame(\n",
    "    {\n",
    "        'uuid': [int(x.split('/')[-1][:-4]) for x in test_path],\n",
    "        'label': pred.argmax(1)\n",
    "})\n",
    "submit['label'] = submit['label'].map({1:'NC', 0: 'MCI'})\n",
    "submit = submit.sort_values(by='uuid')\n",
    "submit.to_csv('submit2.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
